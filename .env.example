# ============================================================
# Autonomous Agent â€” Configuration
# Copy this file to .env and fill in your values
# ============================================================

# --- LLM Provider ---
# Supported: anthropic, openai, ollama
LLM_PROVIDER=anthropic
ANTHROPIC_API_KEY=sk-ant-...
OPENAI_API_KEY=sk-...
# For local models via Ollama
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.1

# Default model per provider
ANTHROPIC_MODEL=claude-sonnet-4-20250514
OPENAI_MODEL=gpt-4o

# --- Channels ---
TELEGRAM_BOT_TOKEN=
DISCORD_BOT_TOKEN=
DISCORD_ALLOWED_CHANNEL_IDS=   # comma-separated

# --- Gateway ---
GATEWAY_PORT=18789
GATEWAY_HOST=127.0.0.1

# --- Heartbeat ---
HEARTBEAT_ENABLED=true
HEARTBEAT_INTERVAL_MINUTES=30
HEARTBEAT_CHANNEL=telegram

# --- Agent ---
AGENT_NAME=Jarvis
AGENT_WORKSPACE=./workspace
AGENT_MAX_TOOL_CALLS=20
AGENT_AUTONOMY_LEVEL=medium     # low | medium | high

# --- Security ---
ALLOWED_USER_IDS=               # comma-separated platform user IDs
SANDBOX_ENABLED=true
GATEWAY_AUTH_ENABLED=true       # require bearer token for gateway
SSRF_PROTECTION_ENABLED=true    # block requests to internal networks
PROMPT_INJECTION_GUARDS=true    # wrap untrusted content with boundary markers
AUDIT_LOG_ENABLED=true          # persistent log of all tool calls
SHELL_TIMEOUT_MS=30000          # max shell command duration
MAX_TOOL_OUTPUT_CHARS=50000     # cap tool output to prevent context flooding
GATEWAY_RATE_LIMIT_PER_MIN=60
LLM_RATE_LIMIT_PER_MIN=30
MAX_REQUEST_BODY_BYTES=1048576  # 1 MB
